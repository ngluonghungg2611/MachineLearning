{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python390jvsc74a57bd0dcacb0086e9a4f4eabd41c33bf4faac5ea0a3337ed3f5eff0680afa930572c04",
   "display_name": "Python 3.9.0 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 30000 entries, 0 to 29999\nData columns (total 25 columns):\n #   Column                      Non-Null Count  Dtype  \n---  ------                      --------------  -----  \n 0   ID                          30000 non-null  int64  \n 1   LIMIT_BAL                   30000 non-null  float64\n 2   SEX                         30000 non-null  int64  \n 3   EDUCATION                   30000 non-null  int64  \n 4   MARRIAGE                    30000 non-null  int64  \n 5   AGE                         30000 non-null  int64  \n 6   PAY_0                       30000 non-null  int64  \n 7   PAY_2                       30000 non-null  int64  \n 8   PAY_3                       30000 non-null  int64  \n 9   PAY_4                       30000 non-null  int64  \n 10  PAY_5                       30000 non-null  int64  \n 11  PAY_6                       30000 non-null  int64  \n 12  BILL_AMT1                   30000 non-null  float64\n 13  BILL_AMT2                   30000 non-null  float64\n 14  BILL_AMT3                   30000 non-null  float64\n 15  BILL_AMT4                   30000 non-null  float64\n 16  BILL_AMT5                   30000 non-null  float64\n 17  BILL_AMT6                   30000 non-null  float64\n 18  PAY_AMT1                    30000 non-null  float64\n 19  PAY_AMT2                    30000 non-null  float64\n 20  PAY_AMT3                    30000 non-null  float64\n 21  PAY_AMT4                    30000 non-null  float64\n 22  PAY_AMT5                    30000 non-null  float64\n 23  PAY_AMT6                    30000 non-null  float64\n 24  default.payment.next.month  30000 non-null  int64  \ndtypes: float64(13), int64(12)\nmemory usage: 5.7 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "dataset = pd.read_csv('UCI_Credit_Card.csv', header = 0, encoding='utf-8', engine='python')\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of data train is: (10500, 25)\nShape os data values is: (2100, 25)\nShape os data dev is: (2100, 25)\nShape of data test is: (2100, 25)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Phân chia train/val/train/test\n",
    "'''\n",
    "import numpy as np \n",
    "model_features = list(set(dataset.columns).difference({\"ID\", \"default.payment.next.month\"}))\n",
    "target = [\"default.payment.next.month\"]\n",
    "x = dataset[model_features]\n",
    "y = dataset[target]\n",
    "\n",
    "id_pos = np.where(y.values.reshape(-1) == 1)[0]\n",
    "id_neg = np.where(y.values.reshape(-1) == 0)[0]\n",
    "\n",
    "np.random.shuffle(id_pos)\n",
    "np.random.shuffle(id_neg)\n",
    "\n",
    "#   Tập train\n",
    "id_train_neg = id_neg[:10000]\n",
    "id_train_pos = id_pos[:500]\n",
    "id_train = np.concatenate((id_train_neg, id_train_pos), axis = 0 )\n",
    "\n",
    "#   Tập val\n",
    "id_val_neg = id_neg[10000:12000]\n",
    "id_val_pos = id_pos[500:600]\n",
    "id_val = np.concatenate((id_val_neg, id_val_pos), axis = 0)\n",
    "\n",
    "\n",
    "#   Tập dev\n",
    "id_dev_neg = id_neg[12000:14000]\n",
    "id_dev_pos = id_pos[600:700]\n",
    "id_dev = np.concatenate((id_dev_neg, id_dev_pos), axis =0)\n",
    "\n",
    "#   Tập test\n",
    "id_test_neg = id_neg[14000:16000]\n",
    "id_test_pos = id_pos[700:800]\n",
    "id_test = np.concatenate((id_test_neg, id_test_pos), axis=0)\n",
    "\n",
    "#   Khởi tạp dataset\n",
    "\n",
    "data_train = dataset.iloc[id_train]\n",
    "data_val = dataset.iloc[id_val]\n",
    "data_dev = dataset.iloc[id_dev]\n",
    "data_test = dataset.iloc[id_test]\n",
    "\n",
    "#   Output shape all dataset\n",
    "print('Shape of data train is: {}'.format(data_train.shape))\n",
    "print('Shape os data values is: {}'.format(data_val.shape))\n",
    "print('Shape os data dev is: {}'.format(data_dev.shape))\n",
    "print('Shape of data test is: {}'.format(data_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Build Model\n",
    "'''\n",
    "import numpy as np \n",
    "from sklearn.calibration import calibration_curve, CalibratedClassifierCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "model 1 ROC score on dev dataset:  0.7402074999999999\n",
      "model 2 ROC score on dev dataset:  0.745485\n",
      "model 3 ROC score on dev dataset:  0.7486649999999999\n"
     ]
    }
   ],
   "source": [
    "model1 = RandomForestClassifier(n_estimators=100, max_depth=5, min_samples_split=200, class_weight=None, max_features=10)\n",
    "\n",
    "model2 = RandomForestClassifier(n_estimators=500, max_depth=10, min_samples_split=400, random_state=12, class_weight='balanced', max_features='auto')\n",
    "\n",
    "model3 = RandomForestClassifier(n_estimators=800, max_depth=10, min_samples_split=200, random_state=12, class_weight='balanced', max_features='sqrt')\n",
    "\n",
    "def _tunning_model(model, X_train, y_train, X_dev, y_dev):\n",
    "    model.fit(X_train, y_train)\n",
    "    model_predictions = model.predict_proba(X_dev)\n",
    "    model_roc_score = roc_auc_score(y_dev, model_predictions[:,1])\n",
    "    return model, model_roc_score\n",
    "\n",
    "model1, model1_roc_score = _tunning_model(model1, data_train[model_features],\n",
    "                                                  data_train['default.payment.next.month'],\n",
    "                                                  data_dev[model_features],\n",
    "                                                  data_dev['default.payment.next.month'])\n",
    "print('model 1 ROC score on dev dataset: ', model1_roc_score)\n",
    "\n",
    "model2, model2_roc_score = _tunning_model(model2, data_train[model_features],\n",
    "                                                  data_train['default.payment.next.month'],\n",
    "                                                  data_dev[model_features],\n",
    "                                                  data_dev['default.payment.next.month'])\n",
    "print('model 2 ROC score on dev dataset: ', model2_roc_score)\n",
    "\n",
    "model3, model3_roc_score = _tunning_model(model3, data_train[model_features],\n",
    "                                                  data_train['default.payment.next.month'],\n",
    "                                                  data_dev[model_features],\n",
    "                                                  data_dev['default.payment.next.month'])\n",
    "print('model 3 ROC score on dev dataset: ', model3_roc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Mô hình 2 là mô hình tốt nhất nên chọn mô hình 2 là baseline kèm với nhứng siêu tham số được giữ đểkhởi tạp các mô hình sau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Under Slamping\n",
    "'''\n",
    "#   Phan chia mẫu ngẫu nhiên theo tỉ lệ 80:20\n",
    "id_train_neg_80_20 = id_train_neg[:2000]\n",
    "id_train_80_20 = np.concatenate((id_train_neg_80_20, id_train_pos), axis=0)\n",
    "\n",
    "#   Phân chia mẫu ngẫu nhiên theo tỉ lệ 70:30\n",
    "id_train_neg_70_30 = id_train_neg[:1166]\n",
    "id_train_70_30 = np.concatenate((id_train_neg_70_30, id_train_pos), axis=0)\n",
    "\n",
    "#   Khởi tạo dataset \n",
    "data_train_80_20 = dataset.iloc[id_train_80_20]\n",
    "data_train_70_30 = dataset.iloc[id_train_70_30]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "model2_unsam_80_20 roc score on test:  0.8254925000000001\n",
      "model2_unsam_80_20 f1 score on test:  0.23270440251572327\n",
      "model2_unsam_70_30 roc score on test:  0.8211350000000001\n",
      "model2_unsam_70_30 f1 score on test:  0.2191780821917808\n"
     ]
    }
   ],
   "source": [
    "#   Huấn luyện mô hình\n",
    "model2_unsam_80_20 = RandomForestClassifier(n_estimators=500, max_depth=10, min_samples_split=400, random_state=12, class_weight=\"balanced\", max_features=\"auto\")\n",
    "model2_unsam_80_20.fit( data_train_80_20[model_features], data_train_80_20['default.payment.next.month'] )\n",
    "model_predictions = model2_unsam_80_20.predict_proba(data_test[model_features])\n",
    "model_pred_label = model2_unsam_80_20.predict(data_test[model_features])\n",
    "model_roc_score = roc_auc_score(data_test['default.payment.next.month'], model_predictions[:,1])\n",
    "model_f1_score = f1_score(data_test['default.payment.next.month'], model_pred_label)\n",
    "\n",
    "print('model2_unsam_80_20 roc score on test: ', model_roc_score)\n",
    "print('model2_unsam_80_20 f1 score on test: ', model_f1_score)\n",
    "\n",
    "#   Huấn luyện mô hình 70_30\n",
    "model2_unsam_70_30 = RandomForestClassifier(n_estimators=500, max_depth=10, min_samples_split=400, random_state=12, class_weight=\"balanced\", max_features=\"auto\")\n",
    "model2_unsam_70_30.fit(data_train_70_30[model_features], data_train_70_30['default.payment.next.month'])\n",
    "model_predictions = model2_unsam_70_30.predict_proba(data_test[model_features])\n",
    "model_pred_label = model2_unsam_70_30.predict(data_test[model_features])\n",
    "model_roc_score = roc_auc_score(data_test['default.payment.next.month'], model_predictions[:,1])\n",
    "model_f1_score = f1_score(data_test['default.payment.next.month'], model_pred_label)\n",
    "\n",
    "print('model2_unsam_70_30 roc score on test: ', model_roc_score)\n",
    "print('model2_unsam_70_30 f1 score on test: ', model_f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "random forest roc score on test:  0.8345350000000001\nrandom forest f1 score on test:  0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Dự báo mô hình trên tập test và tính toán các chỉ số auc và f1 score.\n",
    "'''\n",
    "model_predictions = model2.predict_proba(data_test[model_features])\n",
    "model_pred_label = model2.predict(data_test[model_features]) \n",
    "model_roc_score = roc_auc_score(data_test['default.payment.next.month'], model_predictions[:,1])\n",
    "model_f1_score = f1_score(data_test['default.payment.next.month'], model_pred_label)\n",
    "\n",
    "print('random forest roc score on test: ', model_roc_score)\n",
    "print('random forest f1 score on test: ', model_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_4 (InputLayer)         [(None, 23)]              0         \n_________________________________________________________________\ndense_9 (Dense)              (None, 128)               3072      \n_________________________________________________________________\ndropout_6 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_10 (Dense)             (None, 64)                8256      \n_________________________________________________________________\ndropout_7 (Dropout)          (None, 64)                0         \n_________________________________________________________________\ndense_11 (Dense)             (None, 1)                 65        \n=================================================================\nTotal params: 11,393\nTrainable params: 11,393\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# # concate nate all layers\n",
    "# encode_els = concatenate(encode_els) \n",
    "inputlayer = Input(shape=(23,))\n",
    "hidden1 = Dense(units = 128, kernel_initializer = 'normal', activation = 'relu')(inputlayer)\n",
    "droplayer1 = Dropout(0.8)(hidden1)\n",
    "hidden2 = Dense(64, kernel_initializer = 'normal', activation = 'relu')(droplayer1)\n",
    "droplayer2 = Dropout(0.2)(hidden2)\n",
    "outputlayer = Dense(1, kernel_initializer = 'normal', activation = 'sigmoid')(droplayer2)\n",
    "mlp_classifier = Model(inputs = inputlayer, outputs = [outputlayer])\n",
    "mlp_classifier.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "165/165 [==============================] - 1s 2ms/step - loss: 192.1925 - accuracy: 0.8990 - val_loss: 21.6276 - val_accuracy: 0.9524\n",
      "Epoch 2/10\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 33.5148 - accuracy: 0.9064 - val_loss: 8.0490 - val_accuracy: 0.9524\n",
      "Epoch 3/10\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 14.8427 - accuracy: 0.9163 - val_loss: 3.7490 - val_accuracy: 0.9524\n",
      "Epoch 4/10\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 6.8975 - accuracy: 0.9244 - val_loss: 1.5071 - val_accuracy: 0.9519\n",
      "Epoch 5/10\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 3.8640 - accuracy: 0.9299 - val_loss: 1.0088 - val_accuracy: 0.9524\n",
      "Epoch 6/10\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 2.5673 - accuracy: 0.9308 - val_loss: 0.6978 - val_accuracy: 0.9490\n",
      "Epoch 7/10\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 1.5434 - accuracy: 0.9348 - val_loss: 0.5453 - val_accuracy: 0.9524\n",
      "Epoch 8/10\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 1.0376 - accuracy: 0.9403 - val_loss: 0.5380 - val_accuracy: 0.9524\n",
      "Epoch 9/10\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.5841 - accuracy: 0.9454 - val_loss: 0.4572 - val_accuracy: 0.9524\n",
      "Epoch 10/10\n",
      "165/165 [==============================] - 0s 1ms/step - loss: 0.4230 - accuracy: 0.9496 - val_loss: 0.4179 - val_accuracy: 0.9524\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x175b37d0880>"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "\n",
    "optimizer = Adam()\n",
    "mlp_classifier.compile(optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "mlp_classifier.fit(data_train[model_features], data_train['default.payment.next.month'],\n",
    "                   validation_data = (data_val[model_features], data_val['default.payment.next.month']),\n",
    "                   epochs = 10,\n",
    "                   batch_size = 64)"
   ]
  }
 ]
}