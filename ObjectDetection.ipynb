{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ObjectDetection.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPAotRmKEtQIqwhOz0h1sBs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"NhJ2lIRaufc6"},"source":["# **Anchor Box**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":345},"id":"Tj1wbOpKuZmW","executionInfo":{"status":"error","timestamp":1621872131633,"user_tz":-420,"elapsed":639,"user":{"displayName":"Hùng Nguyễn Lương","photoUrl":"","userId":"01503746792650000386"}},"outputId":"d4bab96d-e695-49ec-9525-c58f3f071381"},"source":["from __future__ import division\n","import numpy as np\n","import keras.backend as K\n","from keras.engine.topology import InputSpec\n","from keras.engine.topology import Layer\n"],"execution_count":27,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-9787f527b1bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopology\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopology\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbounding_box_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbounding_box_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_coordinates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bounding_box_utils'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rVQ8KPVmIigG","executionInfo":{"status":"ok","timestamp":1621872531711,"user_tz":-420,"elapsed":3079,"user":{"displayName":"Hùng Nguyễn Lương","photoUrl":"","userId":"01503746792650000386"}},"outputId":"7ddcfc3e-b8fb-4748-ec08-df5209c26324"},"source":["!pip install pyproj\n","from pyproj import transform\n"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pyproj in /usr/local/lib/python3.7/dist-packages (3.1.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from pyproj) (2020.12.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FJKC6TScLTnJ","executionInfo":{"status":"ok","timestamp":1621873216018,"user_tz":-420,"elapsed":293,"user":{"displayName":"Hùng Nguyễn Lương","photoUrl":"","userId":"01503746792650000386"}}},"source":["def convert_coordinates(tensor, start_index, conversion, border_pixels='half'):\n","    '''\n","    Convert coordinates for axis-aligned 2D boxes between two coordinate formats.\n","    Creates a copy of `tensor`, i.e. does not operate in place. Currently there are\n","    three supported coordinate formats that can be converted from and to each other:\n","        1) (xmin, xmax, ymin, ymax) - the 'minmax' format\n","        2) (xmin, ymin, xmax, ymax) - the 'corners' format\n","        2) (cx, cy, w, h) - the 'centroids' format\n","    Arguments:\n","        tensor (array): A Numpy nD array containing the four consecutive coordinates\n","            to be converted somewhere in the last axis.\n","        start_index (int): The index of the first coordinate in the last axis of `tensor`.\n","        conversion (str, optional): The conversion direction. Can be 'minmax2centroids',\n","            'centroids2minmax', 'corners2centroids', 'centroids2corners', 'minmax2corners',\n","            or 'corners2minmax'.\n","        border_pixels (str, optional): How to treat the border pixels of the bounding boxes.\n","            Can be 'include', 'exclude', or 'half'. If 'include', the border pixels belong\n","            to the boxes. If 'exclude', the border pixels do not belong to the boxes.\n","            If 'half', then one of each of the two horizontal and vertical borders belong\n","            to the boxex, but not the other.\n","    Returns:\n","        A Numpy nD array, a copy of the input tensor with the converted coordinates\n","        in place of the original coordinates and the unaltered elements of the original\n","        tensor elsewhere.\n","    '''\n","    if border_pixels == 'half':\n","        d = 0\n","    elif border_pixels == 'include':\n","        d = 1\n","    elif border_pixels == 'exclude':\n","        d = -1\n","\n","    ind = start_index\n","    tensor1 = np.copy(tensor).astype(np.float)\n","    if conversion == 'minmax2centroids':\n","        tensor1[..., ind] = (tensor[..., ind] + tensor[..., ind+1]) / 2.0 # Set cx\n","        tensor1[..., ind+1] = (tensor[..., ind+2] + tensor[..., ind+3]) / 2.0 # Set cy\n","        tensor1[..., ind+2] = tensor[..., ind+1] - tensor[..., ind] + d # Set w\n","        tensor1[..., ind+3] = tensor[..., ind+3] - tensor[..., ind+2] + d # Set h\n","    elif conversion == 'centroids2minmax':\n","        tensor1[..., ind] = tensor[..., ind] - tensor[..., ind+2] / 2.0 # Set xmin\n","        tensor1[..., ind+1] = tensor[..., ind] + tensor[..., ind+2] / 2.0 # Set xmax\n","        tensor1[..., ind+2] = tensor[..., ind+1] - tensor[..., ind+3] / 2.0 # Set ymin\n","        tensor1[..., ind+3] = tensor[..., ind+1] + tensor[..., ind+3] / 2.0 # Set ymax\n","    elif conversion == 'corners2centroids':\n","        tensor1[..., ind] = (tensor[..., ind] + tensor[..., ind+2]) / 2.0 # Set cx\n","        tensor1[..., ind+1] = (tensor[..., ind+1] + tensor[..., ind+3]) / 2.0 # Set cy\n","        tensor1[..., ind+2] = tensor[..., ind+2] - tensor[..., ind] + d # Set w\n","        tensor1[..., ind+3] = tensor[..., ind+3] - tensor[..., ind+1] + d # Set h\n","    elif conversion == 'centroids2corners':\n","        tensor1[..., ind] = tensor[..., ind] - tensor[..., ind+2] / 2.0 # Set xmin\n","        tensor1[..., ind+1] = tensor[..., ind+1] - tensor[..., ind+3] / 2.0 # Set ymin\n","        tensor1[..., ind+2] = tensor[..., ind] + tensor[..., ind+2] / 2.0 # Set xmax\n","        tensor1[..., ind+3] = tensor[..., ind+1] + tensor[..., ind+3] / 2.0 # Set ymax\n","    elif (conversion == 'minmax2corners') or (conversion == 'corners2minmax'):\n","        tensor1[..., ind+1] = tensor[..., ind+2]\n","        tensor1[..., ind+2] = tensor[..., ind+1]\n","    else:\n","        raise ValueError(\"Unexpected conversion value. Supported values are 'minmax2centroids', 'centroids2minmax', 'corners2centroids', 'centroids2corners', 'minmax2corners', and 'corners2minmax'.\")\n","\n","    return tensor1\n"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"4zc3DJBVvoiC"},"source":["class AnchorBoxes(Layer):\n","  '''\n","  - Tác dụng: Tạo ra một output tensor chứa tọa độ của các anchor box và các biến\n","    thể dựa trên input tensor. Một tợp hợp các 2D anchor boxes được tạo ra dựa \n","    trên aspect ratios và scale trên mỗi một cells của grid cells. Các hộp được \n","    tham số hóa bằng các tọa độ `(xmin, xmax, ymin, ymax)`\n","    \n","  - Input shape:\n","        4D tensor shape `(batch, channels, height, width)` nếu `dim_ordering = 'th'`\n","        or `(batch, height, width, channels)` nếu `dim_ordering = 'tf'`.\n","\n","  - Output shape:\n","        5D tensor of shape `(batch, height, width, n_boxes, 8)`. \n","        Chiều cuối cùng gồm 4 tọa độ của anchor box và 4 giá trị biến thể ở mỗi box.\n","    '''\n","    def __init__(self,\n","                img_height,\n","                img_width,\n","                this_scale,\n","                next_scale,\n","                aspect_ratios = [0.5, 1.0, 2.0],\n","                two_boxes_for_ar1 = True,\n","                this_steps = None,\n","                this_offsets = None,\n","                clip_boxes = False,\n","                variances = [0.1, 0.1, 0.2, 0.2],\n","                coords = 'centroids',\n","                normalize_coords = False,\n","                **kwargs):\n","        '''\n","\n","        Arguments:\n","            - img_height (int): chiều cao input images.\n","            - img_width (int): chiều rộng input images.\n","            - this_scale (float): một giá trị float thuộc [0, 1], nhân tố scaling kích thước để tạo các anchor boxes dựa trên một tỷ lệ so với cạnh ngắn hơn trong width và height.\n","            - next_scale (float): giá trị tiếp theo của scale. Được thiết lập khi vào chỉ khi\n","                `self.two_boxes_for_ar1 == True`.\n","            - aspect_ratios (list, optional): tợp hợp các aspect ratios của các default boxes được tạo ra từ layer này.\n","            - two_boxes_for_ar1 (bool, optional): Được sử dụng chỉ khi `aspect_ratios` = 1.\n","                Nếu `True`, hai default boxes được tạo ra khi aspect ratio = 1. default box đầu tiên sử dụng scaling factor của layer tương ứng,\n","                default box thứ 2 sử dụng trung bình hình học giữa scaling factor và next scaling factor.\n","            - clip_boxes (bool, optional): Nếu đúng `True`, giới hạn tọa độ anchor box nằm bên trong hình ảnh.\n","            - variances (list, optional): Tợp hợp gồm 4 giá trị floats > 0. Là các anchor box offset tương ứng với mỗi tọa độ chia cho giá trị variances tương ứng của nó.\n","            - coords (str, optional): Tọa độ của box được sử dụng trong model. Có thể là centroids định dạng `(cx, cy, w, h)` (tọa độ box center, width, height),\n","                hoặc 'corners' định dạng `(xmin, ymin, xmax,  ymax)`, hoặc 'minmax' định dạng `(xmin, xmax, ymin, ymax)`.\n","            - normalize_coords (bool, optional): Nếu `True` mô hình sử dụng tọa độ tương đối thay vì tuyệt đối. Chẳng hạn mô hình dự đoán tọa độ nằm trong [0, 1] thay vì tọa độ tuyệt đối.\n","        '''\n","        if K.backend() != 'tensorflow':\n","            raise TypeError(\"This layer inly support TensorFlow at the moment, but you are using {} backend.\".format(K.backend()))\n","\n","        if (this_scale < 0) of (next_scale < 0) of (this_scale > 1):\n","            raise ValueError(\"'this_scale' must be [0,1] and 'next_scale' must be > 0, but 'this_scale' == {}, 'next_scale' == {}\".format(this_scale, next_scale))\n","\n","        if len(variances) != 4: \n","            raise ValueError(\"4 variances values must be passed, but {} values were recieved.\".format(len(variances)))\n","        variances = np.array(variances)\n","        if np.any(variances <= 0):\n","            raise ValueError(\"All variances must be > 0, but the variances given are {}\".format(variances))\n","        \n","\n","        self.img_height = img_height\n","        self.img_width = img_width\n","        self.this_scale = this_scale\n","        self.next_scale = next_scale\n","        self.aspect_ratios = aspect_ratios\n","        self.two_boxes_for_ar1 = two_boxes_for_ar1\n","        self.this_offsets = this_offsets\n","        self.this_steps = this_steps\n","        self.clip_boxes = clip_boxes\n","        self.variances = variances\n","        self.coords = coords\n","        self.normalize_coords = normalize_coords\n","        \n","        #Tính toán sô lượng box trên 1 cell trường aspect_ratios =1 thì thêm 1 box\n","        if (1 in aspect_ratios) and two_boxes_for_ar1:\n","            self.n_boxes = len(aspect_ratios) + 1\n","        else: \n","            self.n_boxes = len(aspect_ratios)\n","        super(AnchorBoxes, self).__init__(**kwargs)\n","    \n","\n","    def build(self, input_shape):\n","        self.input_spec = [InputSpec(shape=input_shape)]\n","        super(AnchorBoxes, self).build(input_shape)\n","    \n","\n","    def call(self, x, mask = None):\n","        '''\n","        Return: Trả về 1 anchor box tensor dựa trên shape của input tensor.\n","\n","        Tensor này được thiết kế như là hằng số và không tham gia vào quá trình tính toán.\n","\n","        Arguments:\n","            x (tensor): 4D tensor có shape `(batch, channels, height, width)` nếu `dim_ordering = 'th'`\n","                hoặc `(batch, height, width, channels)` nếu `dim_ordering = 'tf'`. Input cho layer này phải là output của các localization predictor layer.\n","        '''\n","        #####################################################\n","        # Bước 1: Tính toán with và heigth của box với mỗi aspect ratio\n","        #####################################################\n","        # Cạnh ngẵn hơn của hình ảnh có thể được sử dụng để tính `w` và `h` sử dụng `scale` và `aspect_ratios`.\n","        size = min(self.img_height, self.img_width)\n","        #TÍnh toán box (w,h) cho toàn bộ aspect ratios\n","        wh_list = []\n","        for ar in slef.aspect_ratios:\n","            if ar == 1:\n","                #Tính anchor box thông thường khi aspect_ratio =1.\n","                box_height = box_width = self.this_scale*size\n","                wh_list.append((box_width,box_height))\n","                if self.two_boxes_for_ar1:\n","                    #Tính version lớn hơn cảu anchor box sử dụng the gometric mean của scale và next scale\n","                    box_height = box_width = np.sqrt(self.this_scale*next_scale)*size\n","                    wh_list.append((box_width, box_height))\n","            else:\n","                #trường hợp còn lại box_h = scale*size/sqrt(aspect_ratio) và box_w = scale*size*sqrt(aspect_ratio)\n","                box_width = self.this_scale*size*np.sqrt(ar)\n","                box_height = self.this_scale*size//np.sqrt(ar)\n","                wh_list.append((box_width, box_height))\n","        \n","        #append vào wh_list\n","        wh_list = np.array(wh_list)\n","\n","        #Định hình input_shape\n","        if K.common.image_dim_ordering() == 'tf':\n","            batch_size, feature_map_height, feature_map_width, feature_map_channels = x.get_shape().as_list()\n","        else:\n","            batch_size, feature_map_channels, feature_map_height, feature_map_width = x.get_shape().as_list()\n","\n","        \n","        #Tính các center points của grid of box: CHúng là duy nhất đối với  aspect ratios.\n","        #########################################################\n","        #Bước 2: Tính các step size. Khoảng cách là bao xa giữa các anchor box center point theo chiều w và h\n","        ########################################################\n","        if (self.this_scale is None):\n","            step_height = self.img_height // feature_map_height\n","            step_width = self.img_width // feature_map_width\n","        else:\n","            if isinstance(self.this_steps, (list, tuple)) and (len(self.this_steps) == 2):\n","                step_height = self.this_steps[0]\n","                strp_width = self.this_steps[1]\n","            elif isinstance(self.this_steps, (int, float)):\n","                step_height = self.this_steps\n","                step_width = self.this_steps\n","        #Tính toán các offsets cho anchor box conter point đầu tiên từ góc trên cùng bên trái của hình ảnh\n","        if self.this_offsets is None:\n","            offset_height = 0.5\n","            offset_width = 0.5\n","        else:\n","            if isinstance(self.this_offsets, (list, tuple)) and (len(self.this_offsets) == 2):\n","                offset_height = self.this_offsets[0]\n","                offset_width = self.this_offsets[1]\n","            elif isinstance(self.this_offsets, (int, float)):\n","                offset_height self.this_offsets\n","                offset_width = self.this_offsets\n","        \n","\n","        ###############################################################\n","        # Bước 3: Tính toán các tọa độ của (cx, cy, w, h) theo tọa độ cỉa image gốc.\n","        ############################################################\n","        # bây giờ chúng ta có các offsets và step_size, tính grid của anchor box center point\n","        cx = np.linspace(offset_width*step_width, (offset_width + feature_map_width -1)*step_width, feature_map_width)\n","        cy = np.linspace(offset_height*step_height, (offset_height + feature_map_height -1)*step_height, feature_map_height)\n","        cx_grid, cy_grid = np.meshgrid(cx, cy)\n","        cx_grid = np.expand_dims(cx_grid, -1)\n","        cy_grid = np.expand_dims(cy_grid, -1)\n","\n","\n","\n","        #Tạo 1 4D tensor có shape '(feature_map_height, feature_map_width, n_boxes, 4)'\n","        #Chiều cuối cùng sẽ chứa '(cx, cy, w, h)'\n","\n","        boxes_tensor = np.zeros((feature_map_height, feature_map_width,, self.n_boxes, 4))\n","\n","        boxes_tensor[:, :, :, 0] = np.tile(cx_grid, (1, 1, self.n_boxes)) #Đặt cx\n","        boxes_tensor[:, :, :, 1] = np.tile(cy_grid, (1, 1, self.n_boxes)) #Đặt cy\n","        boxes_tensor[:, :, :, 2] = wh_list[:, 0] #Đặt w\n","        boxes_tensor[:, :, :, 3] = wh_list[:, 1] #Đặt h\n","\n","        #Chuyển '(cx, cy, w, h)' sang '(xmin, xmax, ymin, ymax)'\n","        boxes_tensor = convert_coordinates(boxes_tensor, start_index=0, conversion='centroids2corners')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eXEdyV_RuxyS","executionInfo":{"status":"ok","timestamp":1621866367694,"user_tz":-420,"elapsed":255,"user":{"displayName":"Hùng Nguyễn Lương","photoUrl":"","userId":"01503746792650000386"}}},"source":[""],"execution_count":19,"outputs":[]}]}