{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Build_AnchorBoxes_Object_Dectection.ipynb","provenance":[{"file_id":"1RHUmjXHK-ruWj1pffds0ao6Ao5wbstJ5","timestamp":1621959965687}],"collapsed_sections":[],"authorship_tag":"ABX9TyM0TcBXo+G1mhPtWtFIapCV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"NhJ2lIRaufc6"},"source":["# **Anchor Box**"]},{"cell_type":"code","metadata":{"id":"Tj1wbOpKuZmW"},"source":["from __future__ import division\n","import numpy as np\n","import keras.backend as K\n","from keras.engine.topology import InputSpec\n","from keras.engine.topology import Layer\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FJKC6TScLTnJ"},"source":["def convert_coordinates(tensor, start_index, conversion, border_pixels='half'):\n","    '''\n","    Convert coordinates for axis-aligned 2D boxes between two coordinate formats.\n","    Creates a copy of `tensor`, i.e. does not operate in place. Currently there are\n","    three supported coordinate formats that can be converted from and to each other:\n","        1) (xmin, xmax, ymin, ymax) - the 'minmax' format\n","        2) (xmin, ymin, xmax, ymax) - the 'corners' format\n","        2) (cx, cy, w, h) - the 'centroids' format\n","    Arguments:\n","        tensor (array): A Numpy nD array containing the four consecutive coordinates\n","            to be converted somewhere in the last axis.\n","        start_index (int): The index of the first coordinate in the last axis of `tensor`.\n","        conversion (str, optional): The conversion direction. Can be 'minmax2centroids',\n","            'centroids2minmax', 'corners2centroids', 'centroids2corners', 'minmax2corners',\n","            or 'corners2minmax'.\n","        border_pixels (str, optional): How to treat the border pixels of the bounding boxes.\n","            Can be 'include', 'exclude', or 'half'. If 'include', the border pixels belong\n","            to the boxes. If 'exclude', the border pixels do not belong to the boxes.\n","            If 'half', then one of each of the two horizontal and vertical borders belong\n","            to the boxex, but not the other.\n","    Returns:\n","        A Numpy nD array, a copy of the input tensor with the converted coordinates\n","        in place of the original coordinates and the unaltered elements of the original\n","        tensor elsewhere.\n","    '''\n","    if border_pixels == 'half':\n","        d = 0\n","    elif border_pixels == 'include':\n","        d = 1\n","    elif border_pixels == 'exclude':\n","        d = -1\n","\n","    ind = start_index\n","    tensor1 = np.copy(tensor).astype(np.float)\n","    if conversion == 'minmax2centroids':\n","        tensor1[..., ind] = (tensor[..., ind] + tensor[..., ind+1]) / 2.0 # Set cx\n","        tensor1[..., ind+1] = (tensor[..., ind+2] + tensor[..., ind+3]) / 2.0 # Set cy\n","        tensor1[..., ind+2] = tensor[..., ind+1] - tensor[..., ind] + d # Set w\n","        tensor1[..., ind+3] = tensor[..., ind+3] - tensor[..., ind+2] + d # Set h\n","    elif conversion == 'centroids2minmax':\n","        tensor1[..., ind] = tensor[..., ind] - tensor[..., ind+2] / 2.0 # Set xmin\n","        tensor1[..., ind+1] = tensor[..., ind] + tensor[..., ind+2] / 2.0 # Set xmax\n","        tensor1[..., ind+2] = tensor[..., ind+1] - tensor[..., ind+3] / 2.0 # Set ymin\n","        tensor1[..., ind+3] = tensor[..., ind+1] + tensor[..., ind+3] / 2.0 # Set ymax\n","    elif conversion == 'corners2centroids':\n","        tensor1[..., ind] = (tensor[..., ind] + tensor[..., ind+2]) / 2.0 # Set cx\n","        tensor1[..., ind+1] = (tensor[..., ind+1] + tensor[..., ind+3]) / 2.0 # Set cy\n","        tensor1[..., ind+2] = tensor[..., ind+2] - tensor[..., ind] + d # Set w\n","        tensor1[..., ind+3] = tensor[..., ind+3] - tensor[..., ind+1] + d # Set h\n","    elif conversion == 'centroids2corners':\n","        tensor1[..., ind] = tensor[..., ind] - tensor[..., ind+2] / 2.0 # Set xmin\n","        tensor1[..., ind+1] = tensor[..., ind+1] - tensor[..., ind+3] / 2.0 # Set ymin\n","        tensor1[..., ind+2] = tensor[..., ind] + tensor[..., ind+2] / 2.0 # Set xmax\n","        tensor1[..., ind+3] = tensor[..., ind+1] + tensor[..., ind+3] / 2.0 # Set ymax\n","    elif (conversion == 'minmax2corners') or (conversion == 'corners2minmax'):\n","        tensor1[..., ind+1] = tensor[..., ind+2]\n","        tensor1[..., ind+2] = tensor[..., ind+1]\n","    else:\n","        raise ValueError(\"Unexpected conversion value. Supported values are 'minmax2centroids', 'centroids2minmax', 'corners2centroids', 'centroids2corners', 'minmax2corners', and 'corners2minmax'.\")\n","\n","    return tensor1\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4zc3DJBVvoiC"},"source":["class AnchorBoxes(Layer):\n","\n","    def __init__(self,\n","                img_height,\n","                img_width,\n","                this_scale,\n","                next_scale,\n","                aspect_ratios = [0.5, 1.0, 2.0],\n","                two_boxes_for_ar1 = True,\n","                this_steps = None,\n","                this_offsets = None,\n","                clip_boxes = False,\n","                variances = [0.1, 0.1, 0.2, 0.2],\n","                coords = 'centroids',\n","                normalize_coords = False,\n","                **kwargs):\n","        '''\n","\n","        Arguments:\n","            - img_height (int): chiều cao input images.\n","            - img_width (int): chiều rộng input images.\n","            - this_scale (float): một giá trị float thuộc [0, 1], nhân tố scaling kích thước để tạo các anchor boxes dựa trên một tỷ lệ so với cạnh ngắn hơn trong width và height.\n","            - next_scale (float): giá trị tiếp theo của scale. Được thiết lập khi vào chỉ khi\n","                `self.two_boxes_for_ar1 == True`.\n","            - aspect_ratios (list, optional): tợp hợp các aspect ratios của các default boxes được tạo ra từ layer này.\n","            - two_boxes_for_ar1 (bool, optional): Được sử dụng chỉ khi `aspect_ratios` = 1.\n","                Nếu `True`, hai default boxes được tạo ra khi aspect ratio = 1. default box đầu tiên sử dụng scaling factor của layer tương ứng,\n","                default box thứ 2 sử dụng trung bình hình học giữa scaling factor và next scaling factor.\n","            - clip_boxes (bool, optional): Nếu đúng `True`, giới hạn tọa độ anchor box nằm bên trong hình ảnh.\n","            - variances (list, optional): Tợp hợp gồm 4 giá trị floats > 0. Là các anchor box offset tương ứng với mỗi tọa độ chia cho giá trị variances tương ứng của nó.\n","            - coords (str, optional): Tọa độ của box được sử dụng trong model. Có thể là centroids định dạng `(cx, cy, w, h)` (tọa độ box center, width, height),\n","                hoặc 'corners' định dạng `(xmin, ymin, xmax,  ymax)`, hoặc 'minmax' định dạng `(xmin, xmax, ymin, ymax)`.\n","            - normalize_coords (bool, optional): Nếu `True` mô hình sử dụng tọa độ tương đối thay vì tuyệt đối. Chẳng hạn mô hình dự đoán tọa độ nằm trong [0, 1] thay vì tọa độ tuyệt đối.\n","        '''\n","        if K.backend() != 'tensorflow':\n","            raise TypeError(\"This layer inly support TensorFlow at the moment, but you are using {} backend.\".format(K.backend()))\n","\n","        if (this_scale < 0) or (next_scale < 0) or (this_scale > 1):\n","            raise ValueError(\"'this_scale' must be [0,1] and 'next_scale' must be > 0, but 'this_scale' == {}, 'next_scale' == {}\".format(this_scale, next_scale))\n","\n","        if len(variances) != 4: \n","            raise ValueError(\"4 variances values must be passed, but {} values were recieved.\".format(len(variances)))\n","        variances = np.array(variances)\n","        if np.any(variances <= 0):\n","            raise ValueError(\"All variances must be > 0, but the variances given are {}\".format(variances))\n","        \n","\n","        self.img_height = img_height\n","        self.img_width = img_width\n","        self.this_scale = this_scale\n","        self.next_scale = next_scale\n","        self.aspect_ratios = aspect_ratios\n","        self.two_boxes_for_ar1 = two_boxes_for_ar1\n","        self.this_offsets = this_offsets\n","        self.this_steps = this_steps\n","        self.clip_boxes = clip_boxes\n","        self.variances = variances\n","        self.coords = coords\n","        self.normalize_coords = normalize_coords\n","        \n","        #Tính toán sô lượng box trên 1 cell trường aspect_ratios =1 thì thêm 1 box\n","        if (1 in aspect_ratios) and two_boxes_for_ar1:\n","            self.n_boxes = len(aspect_ratios) + 1\n","        else: \n","            self.n_boxes = len(aspect_ratios)\n","        super(AnchorBoxes, self).__init__(**kwargs)\n","\n","\n","    def build(self, input_shape):\n","        self.input_spec = [InputSpec(shape=input_shape)]\n","        super(AnchorBoxes, self).build(input_shape)\n","\n","\n","    def call(self, x, mask = None):\n","        '''\n","        Return: Trả về 1 anchor box tensor dựa trên shape của input tensor.\n","\n","        Tensor này được thiết kế như là hằng số và không tham gia vào quá trình tính toán.\n","\n","        Arguments:\n","            x (tensor): 4D tensor có shape `(batch, channels, height, width)` nếu `dim_ordering = 'th'`\n","                hoặc `(batch, height, width, channels)` nếu `dim_ordering = 'tf'`. Input cho layer này phải là output của các localization predictor layer.\n","        '''\n","        #####################################################\n","        # Bước 1: Tính toán width và heigth của box với mỗi aspect ratio\n","        #####################################################\n","        # Cạnh ngẵn hơn của hình ảnh có thể được sử dụng để tính `w` và `h` sử dụng `scale` và `aspect_ratios`.\n","        size = min(self.img_height, self.img_width)\n","        #TÍnh toán box (w,h) cho toàn bộ aspect ratios\n","        wh_list = []\n","        for ar in slef.aspect_ratios:\n","            if ar == 1:\n","                #Tính anchor box thông thường khi aspect_ratio =1.\n","                box_height = box_width = self.this_scale*size\n","                wh_list.append((box_width,box_height))\n","                if self.two_boxes_for_ar1:\n","                    #Tính version lớn hơn cảu anchor box sử dụng the gometric mean của scale và next scale\n","                    box_height = box_width = np.sqrt(self.this_scale*next_scale)*size\n","                    wh_list.append((box_width, box_height))\n","            else:\n","                #trường hợp còn lại box_h = scale*size/sqrt(aspect_ratio) và box_w = scale*size*sqrt(aspect_ratio)\n","                box_width = self.this_scale*size*np.sqrt(ar)\n","                box_height = self.this_scale*size//np.sqrt(ar)\n","                wh_list.append((box_width, box_height))\n","        \n","        #append vào wh_list\n","        wh_list = np.array(wh_list)\n","\n","        #Định hình input_shape\n","        if K.common.image_dim_ordering() == 'tf':\n","            batch_size, feature_map_height, feature_map_width, feature_map_channels = x.get_shape().as_list()\n","        else:\n","            batch_size, feature_map_channels, feature_map_height, feature_map_width = x.get_shape().as_list()\n","\n","        \n","        #Tính các center points của grid of box: CHúng là duy nhất đối với  aspect ratios.\n","        #########################################################\n","        #Bước 2: Tính các step size. Khoảng cách là bao xa giữa các anchor box center point theo chiều w và h\n","        ########################################################\n","        if (self.this_scale is None):\n","            step_height = self.img_height // feature_map_height\n","            step_width = self.img_width // feature_map_width\n","        else:\n","            if isinstance(self.this_steps, (list, tuple)) and (len(self.this_steps) == 2):\n","                step_height = self.this_steps[0]\n","                strp_width = self.this_steps[1]\n","            elif isinstance(self.this_steps, (int, float)):\n","                step_height = self.this_steps\n","                step_width = self.this_steps\n","        #Tính toán các offsets cho anchor box conter point đầu tiên từ góc trên cùng bên trái của hình ảnh\n","        if self.this_offsets is None:\n","            offset_height = 0.5\n","            offset_width = 0.5\n","        else:\n","            if isinstance(self.this_offsets, (list, tuple)) and (len(self.this_offsets) == 2):\n","                offset_height = self.this_offsets[0]\n","                offset_width = self.this_offsets[1]\n","            elif isinstance(self.this_offsets, (int, float)):\n","                offset_height = self.this_offsets\n","                offset_width = self.this_offsets\n","        \n","\n","        ###############################################################\n","        # Bước 3: Tính toán các tọa độ của (cx, cy, w, h) theo tọa độ cỉa image gốc.\n","        ############################################################\n","        # bây giờ chúng ta có các offsets và step_size, tính grid của anchor box center point\n","        cx = np.linspace(offset_width*step_width, (offset_width + feature_map_width -1)*step_width, feature_map_width)\n","        cy = np.linspace(offset_height*step_height, (offset_height + feature_map_height -1)*step_height, feature_map_height)\n","        cx_grid, cy_grid = np.meshgrid(cx, cy)\n","        cx_grid = np.expand_dims(cx_grid, -1)\n","        cy_grid = np.expand_dims(cy_grid, -1)\n","\n","\n","\n","        #Tạo 1 4D tensor có shape '(feature_map_height, feature_map_width, n_boxes, 4)'\n","        #Chiều cuối cùng sẽ chứa '(cx, cy, w, h)'\n","\n","        boxes_tensor = np.zeros((feature_map_height, feature_map_width, self.n_boxes, 4))\n","\n","        boxes_tensor[:, :, :, 0] = np.tile(cx_grid, (1, 1, self.n_boxes)) #Đặt cx\n","        boxes_tensor[:, :, :, 1] = np.tile(cy_grid, (1, 1, self.n_boxes)) #Đặt cy\n","        boxes_tensor[:, :, :, 2] = wh_list[:, 0] #Đặt w\n","        boxes_tensor[:, :, :, 3] = wh_list[:, 1] #Đặt h\n","\n","        #Chuyển '(cx, cy, w, h)' sang '(xmin, xmax, ymin, ymax)'\n","        boxes_tensor = convert_coordinates(boxes_tensor, start_index=0, conversion='centroids2corners', border_pixels='half')\n","\n","        #Nếu 'clip_boxes' = true, giới hạn các tọa độ nằm trên boundary của hình ảnh\n","        if self.clip_boxes:\n","            x_coords = boxes_tensor[:, :, :, [0, 2]]\n","            x_coords[x_coords >= self.img_width] = self.img_width -1\n","            x_coords[x_coords < 0] = 0\n","            boxes_tensor[:, :, :, [0, 2]] = x_coords\n","            y_coords = boxes_tensor[:, :, :, [1,3]]\n","            y_coords[y_coords >= self.img_height] = self.img_height -1\n","            y_coords[y_coords < 0] = 0\n","            boxes_tensor[:, :, :, [1,3]] = y_coords\n","\n","        #Nếu 'normalize_coords' == True, chuẩn hóa các tọa độ nằm trong khoảng [0,1]\n","        if self.normalize_coords:\n","            boxes_tensor[:, :, :, [0,2]] /= delf.img_width\n","            boxes_tensor[:, :, :, [1,3]] /= self.img_height\n","        \n","        if self.coords =='centroids':\n","            #COnvert '(xmin, ymin, xmax, ymax)' to (cx, cy, w, h)\n","            boxes_tensor = convert_coordinates(boxes_tensor, start_index=0, conversion='corners2centroids', border_pixels='half')\n","        elif self.coords == 'minmax':\n","            #Convert (xmin, ymin, xmax, ymax) to (xmin, xmax, ymin, ymax)\n","            boxes_tensor = convert_coordinates(boxes_tensor, start_index=0, conversion='corners2minmax', border_pixels='half')\n","\n","        \n","        #Tạo 1 tensor chứa các variances  và append vào boxes_tensor\n","        variances_tensor = np.zeros_like(boxes_tensor) #Shape (feature_map_height, feature_map_width, n_boxes, 4)\n","        variances_tensor += self.variances #Mở rộng thêm Variances\n","        #Bây giờ boxes_tensor trở thành tensoer kích thước (feature_map_height, feature_map_width, n_boxes, 8)\n","        boxes_tensor = np.concatenate((boxes_tensor, variances), axis = -1)\n","\n","        #Bây giờ chuẩn bị 1 chiều cho boxes_tensor đại diện cho batch_size và di chuyển copy theo chiều đó\n","        #Ta được một 5D tensor kích thước (batch_size, feature_map_height, feature_map_width, n_boxes, 8)\n","        boxes_tensor = np.expand_dims(boxes_tensor, axis=0)\n","        boxes_tensor = K.tile(K.constant(boxes_tensor, dtype='float32'), (K.shape(x)[0], 1, 1, 1, 1))\n","\n","        return boxes_tensor\n","    \n","    def compute_output_shape(self, input_shape):\n","        if K.common.image_dim_ordering() == 'tf':\n","            batch_size, feature_map_height, feature_map_width, feature_map_channels = input_shape\n","        else:\n","            batch_size, feature_map_channels, feature_map_height, feature_map_width = input_shape\n","        return (batch_size, feature_map_height, feature_map_width, self.n_boxes, 8)\n","\n","    def get_config(self):\n","        config = {\n","            'img_height': self.img_height,\n","            'img_width': self.img_width,\n","            'this_scale': self.this_scale,\n","            'next_scale': self.next_scale,\n","            'aspect_ratios': list(self.aspect_ratios),\n","            'two_boxes_for_ar1': self.two_boxes_for_ar1,\n","            'clip_boxes': self.clip_boxes,\n","            'variances': self.variances,\n","            'coords': self.coords,\n","            'normalize_coords': self.normalize_coords\n","        }\n","        base_config = super(AnchorBoxes, self).get_config()\n","        return dict(list(base_config.items()) + list(config.items()))"],"execution_count":null,"outputs":[]}]}