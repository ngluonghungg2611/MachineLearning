{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPCO0aW+1xlAxuheHCW/nk6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"VAvfx_t3NlOC"},"source":["\"\"\"\n","1. CÁC THUẬT NGỮ\n","\n","- Đơn vị(unit): là giá trị của 1 điểm nằm trên ma trận khối ở mỗi tầng của mạng CNN.\n","\n","- Vùng nhận thức(Receptive Field): Là vùng ảnh trên khối ma trận đầu vào mà bộ loc \n","  sẽ nhận tích chập để ánh xạ tới một đơn vị trên layer tiếp theo.\n","\n","- Vùng địa phương(Local Region): Theo một ngĩa nào đó sẽ bao hàm cả vùng nhận \n","  thức. Là vùng ảnh cụ thể nằm trên khối ma trận ở các tầng layer của mạng CNN.\n","\n","- Bản đồ đặc trưng(Feature Map): Là ma trận đầu ra khi áp dụng phép tích chập từ\n","  giữa bộ lọc với với các vùng nhận thức theo phương di chuyển từ trái qua phải\n","  và từ trên xuống dưới.\n","\n","- Bản đồ kích hoạt(Activation Map): La output của bản đồ đặc trưng CNN khi áp\n","  dụng thêm hàm #activation để tính đạo hàm phi tuyến\n","\n","2. KIẾN TRÚC CỦA MẠNG NEURAL TÍCH CHẬP\n","- về cơ bản 1 mạng của neural tích chập 2 chiều có dạng như sau:\n","  \n","  intput -> [[conv -> RELU]*N -> POOL?]*M -> [FC -> RELU]*K -> FC\n","\n","- Trong đó:\n","  + input: tầng đầu vào\n","  + conv: tầng tích chập\n","  + RELU: Tầng kích hoạt. Thông qua hàm kích hoạt (activation function), thường la ReLU\n","  + POOL: Tầng tổng hợp, thông thường là MaxPooling \n","  + FC: Fully connected layer- tầng kết nối hoàn toàn. Thông thường tầng này ở cuối \n","    cùng và kết nối với các đơn vị đại diện cho nhóm phân loại   \n","  + M, N, K: số lần lặp lại\n","\n","  => Mạng Neural có 3 quá trình khác nhau: \n","  - Quá trình tích chập - Convoluion\n","  - Quá trình tổng hợp - MaxPooling\n","  - Quá trình kết nối hoàn toàn - Fully connected\n","\n","3. Tính chất cảu mạng Neural tích chập\n","- Tính kết nối trượt: kết nối từng vùng địa phương(local region) hoặc vùng nhận thức (receptive field)\n","  có kích thích bằng với kích thước bộ lọc của hình ảnh đó- TRƯỢT TỪ TRÁI QUA PHẢI, TỪ TRÊN XUỐNG DƯỚI \n","\n","- Các khối Neural 3D được sắp xếp 1 cách hợp lý theo 3 chiều width, height, depth(sâu)\n","\n","- Tính chia sẻ kết nối và kết nối cục bộ: Không kết nối trực tiếp toàn bộ khối 3D\n","  mà sẽ chọn ra các #vùng địa phương(vùng nhận thức) có kích thước bằng với bộ lọc \n","\n","\"\"\"\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Ro0oITqW-_4"},"source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt \n","import logging \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aaYLT6G0WGQM","executionInfo":{"status":"ok","timestamp":1621788458626,"user_tz":-420,"elapsed":2,"user":{"displayName":"Hùng Nguyễn Lương","photoUrl":"","userId":"01503746792650000386"}}},"source":["\n","\n","\n","def cnn_model_fn(feature, labels, mode):\n","    \"\"\" MOdel function for CNN \"\"\"\n","    #input layer\n","    input_layer = tf.reshape(feature['x'], shape=[-1,28,28,1])\n","\n","\n","    #Convolution layer 1\n","    conv1 = tf.layers.conv2d(\n","        inputs = input_layer,\n","        filters = 32,\n","        kernel_size = [5,5],\n","        padding = 'same',\n","        activation = tf.nn.relu\n","    )\n","        #Apply formula:N1 = (N+2P-f)/S + 1\n","        #in which: N is input image size, P is padding size, f is filter size and S is step\n","\n","\n","        #Output tensor shape: N1 = (28-5)/1+1 = 24 => shape = [-1, 24, 24, 1]\n","        #But we at parameter we set padding = 'same' in order to keep output shape unchange to input shape \n","        #Thus output shape is [-1, 28, 28, 1]\n","    \n","    #Max pooling layer 1\n","    pool1 = tf.layers.max_pooling2d(\n","        inputs = conv1,\n","        pool_size = [2,2],\n","        strides = 2\n","    )\n","\n","    #Convolution layer 2\n","    conv2 = tf.layers.conv2d(\n","        inputs = pool1,\n","        filters = 64,\n","        kernel_size = [5,5],\n","        padding = 'same',\n","        activation = tf.nn.relu\n","    )\n","\n","    #Max pooling 2\n","    pool2 = tf.layers.max_pooling2d(\n","        inputs = conv2,\n","        pool_size = [2,2],\n","        strides = 2\n","    )\n","    #Output tensor shape: N4 = (14-2)/2+1 = 7 => shape = [-1, 7, 7, 1]\n","    \n","    #Dense layer\n","    flat = tf.reshape(pool2, [-1, 7*7*64])\n","    dense = tf.layers.dense(\n","        inputs = flat,\n","        units = 1024,\n","        activation = tf.nn.relu\n","    )\n","\n","    dropout = tf.layers.dropout(\n","        inputs = dense,\n","        rate = 0.4,\n","        training = mode == tf.estimator.ModeKeys.TRAIN\n","    )\n","\n","    #Logits layer\n","    logits = tf.layers.dense(_Inputs = dropout, units = 10)\n","\n","    predictions = {\n","        'classes': tf.argmax(input = logits, axis= 1, name = 'class_tensor'),\n","        'probabilities': tf.nn.softmax(logits, name='softmax_tensor')\n","    }\n","    if mode == tf.estimator.ModeKeys.PREDICT:\n","        return tf.estimator.EstimatorSpec(mode = mode, predictions=predictions)\n","    \n","    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits = logits)\n","\n","    if mode == tf.estimator.ModeKeys.TRAIN:\n","        optimizer = tf.train.AdamOptimizer(learining_rate = 0.001)\n","        train_op = optimizer.minimize(\n","            loss = loss,\n","            global_step = tf.train.get_global_step()\n","        )\n","        return tf.estimator.EstimatorSpec(mode=mode, loss = loss, train_op = train_op)\n","    \n","    if mode == tf.estimator.ModeKeys.EVAL:\n","        eval_metric_ops = {\n","            'accuracy': tf.metrics.accuracy(\n","                labels = labels, predictions = predictions['classes']\n","            )\n","        }\n","        return tf.estimator.EstimatorSpec(\n","            mode = mode, loss = loss, eval_metric_ops=eval_metric_ops\n","        )"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"DTr9m5sANm6Z"},"source":["import sys\n","from mnist import MNIST\n","from imutils import path"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XZsrELryXQqh","colab":{"base_uri":"https://localhost:8080/","height":374},"executionInfo":{"status":"error","timestamp":1620886646531,"user_tz":-420,"elapsed":780,"user":{"displayName":"Hùng Nguyễn Lương","photoUrl":"","userId":"01503746792650000386"}},"outputId":"92920539-af6d-4dd7-d1f0-9ff1c78c7d44"},"source":["mndata = MNIST('../input')\n","mndata.load_training()\n","train_data = np.asarray(mndata.train_images)/255.0\n","train_labels = np.array(mndata.test_labels.tolist)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-fefa93beec4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmndata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmndata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmndata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmndata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mnist/loader.py\u001b[0m in \u001b[0;36mload_training\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         ims, labels = self.load(os.path.join(self.path, self.train_img_fname),\n\u001b[0;32m--> 126\u001b[0;31m                                 os.path.join(self.path, self.train_lbl_fname))\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mnist/loader.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, path_img, path_lbl, batch)\u001b[0m\n\u001b[1;32m    245\u001b[0m                                  '(start_point, batch_size)')\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_lbl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m             \u001b[0mmagic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\">II\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmagic\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2049\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mnist/loader.py\u001b[0m in \u001b[0;36mopener\u001b[0;34m(self, path_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_fn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_lbl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/train-labels-idx1-ubyte'"]}]}]}