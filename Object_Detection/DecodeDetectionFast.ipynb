{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DecodeDetectionFast.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO8pNUxNFJ3oKX/nfEPTDPw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"vs0-92oQlf4u","executionInfo":{"status":"ok","timestamp":1621963998171,"user_tz":-420,"elapsed":2507,"user":{"displayName":"Hùng Nguyễn Lương","photoUrl":"","userId":"01503746792650000386"}}},"source":["'''\n","A custom Keras layer to decode the raw SSD prediction output. This is a modified\n","and more efficient version of the `DetectionOutput` layer type in the original Caffe\n","implementation of SSD. For a faithful replication of the original layer, please\n","refer to the `DecodeDetections` layer.\n","Copyright (C) 2018 Pierluigi Ferrari\n","Licensed under the Apache License, Version 2.0 (the \"License\");\n","you may not use this file except in compliance with the License.\n","You may obtain a copy of the License at\n","   http://www.apache.org/licenses/LICENSE-2.0\n","Unless required by applicable law or agreed to in writing, software\n","distributed under the License is distributed on an \"AS IS\" BASIS,\n","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","See the License for the specific language governing permissions and\n","limitations under the License.\n","'''\n","\n","from __future__ import division\n","import numpy as np\n","import tensorflow as tf\n","import keras.backend as K\n","from keras.engine.topology import InputSpec\n","from keras.engine.topology import Layer\n","\n","class DecodeDetectionsFast(Layer):\n","    '''\n","    A Keras layer to decode the raw SSD prediction output.\n","    Input shape:\n","        3D tensor of shape `(batch_size, n_boxes, n_classes + 12)`.\n","    Output shape:\n","        3D tensor of shape `(batch_size, top_k, 6)`.\n","    '''\n","\n","    def __init__(self,\n","                 confidence_thresh=0.01,\n","                 iou_threshold=0.45,\n","                 top_k=200,\n","                 nms_max_output_size=400,\n","                 coords='centroids',\n","                 normalize_coords=True,\n","                 img_height=None,\n","                 img_width=None,\n","                 **kwargs):\n","        '''\n","        All default argument values follow the Caffe implementation.\n","        Arguments:\n","            confidence_thresh (float, optional): A float in [0,1), the minimum classification confidence in a specific\n","                positive class in order to be considered for the non-maximum suppression stage for the respective class.\n","                A lower value will result in a larger part of the selection process being done by the non-maximum suppression\n","                stage, while a larger value will result in a larger part of the selection process happening in the confidence\n","                thresholding stage.\n","            iou_threshold (float, optional): A float in [0,1]. All boxes with a Jaccard similarity of greater than `iou_threshold`\n","                with a locally maximal box will be removed from the set of predictions for a given class, where 'maximal' refers\n","                to the box score.\n","            top_k (int, optional): The number of highest scoring predictions to be kept for each batch item after the\n","                non-maximum suppression stage.\n","            nms_max_output_size (int, optional): The maximum number of predictions that will be left after performing non-maximum\n","                suppression.\n","            coords (str, optional): The box coordinate format that the model outputs. Must be 'centroids'\n","                i.e. the format `(cx, cy, w, h)` (box center coordinates, width, and height). Other coordinate formats are\n","                currently not supported.\n","            normalize_coords (bool, optional): Set to `True` if the model outputs relative coordinates (i.e. coordinates in [0,1])\n","                and you wish to transform these relative coordinates back to absolute coordinates. If the model outputs\n","                relative coordinates, but you do not want to convert them back to absolute coordinates, set this to `False`.\n","                Do not set this to `True` if the model already outputs absolute coordinates, as that would result in incorrect\n","                coordinates. Requires `img_height` and `img_width` if set to `True`.\n","            img_height (int, optional): The height of the input images. Only needed if `normalize_coords` is `True`.\n","            img_width (int, optional): The width of the input images. Only needed if `normalize_coords` is `True`.\n","        '''\n","        if K.backend() != 'tensorflow':\n","            raise TypeError(\"This layer only supports TensorFlow at the moment, but you are using the {} backend.\".format(K.backend()))\n","\n","        if normalize_coords and ((img_height is None) or (img_width is None)):\n","            raise ValueError(\"If relative box coordinates are supposed to be converted to absolute coordinates, the decoder needs the image size in order to decode the predictions, but `img_height == {}` and `img_width == {}`\".format(img_height, img_width))\n","\n","        if coords != 'centroids':\n","            raise ValueError(\"The DetectionOutput layer currently only supports the 'centroids' coordinate format.\")\n","\n","        # We need these members for the config.\n","        self.confidence_thresh = confidence_thresh\n","        self.iou_threshold = iou_threshold\n","        self.top_k = top_k\n","        self.normalize_coords = normalize_coords\n","        self.img_height = img_height\n","        self.img_width = img_width\n","        self.coords = coords\n","        self.nms_max_output_size = nms_max_output_size\n","\n","        # We need these members for TensorFlow.\n","        self.tf_confidence_thresh = tf.constant(self.confidence_thresh, name='confidence_thresh')\n","        self.tf_iou_threshold = tf.constant(self.iou_threshold, name='iou_threshold')\n","        self.tf_top_k = tf.constant(self.top_k, name='top_k')\n","        self.tf_normalize_coords = tf.constant(self.normalize_coords, name='normalize_coords')\n","        self.tf_img_height = tf.constant(self.img_height, dtype=tf.float32, name='img_height')\n","        self.tf_img_width = tf.constant(self.img_width, dtype=tf.float32, name='img_width')\n","        self.tf_nms_max_output_size = tf.constant(self.nms_max_output_size, name='nms_max_output_size')\n","\n","        super(DecodeDetectionsFast, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        self.input_spec = [InputSpec(shape=input_shape)]\n","        super(DecodeDetectionsFast, self).build(input_shape)\n","\n","    def call(self, y_pred, mask=None):\n","        '''\n","        Returns:\n","            3D tensor of shape `(batch_size, top_k, 6)`. The second axis is zero-padded\n","            to always yield `top_k` predictions per batch item. The last axis contains\n","            the coordinates for each predicted box in the format\n","            `[class_id, confidence, xmin, ymin, xmax, ymax]`.\n","        '''\n","\n","        #####################################################################################\n","        # 1. Convert the box coordinates from predicted anchor box offsets to predicted\n","        #    absolute coordinates\n","        #####################################################################################\n","\n","        # Extract the predicted class IDs as the indices of the highest confidence values.\n","        class_ids = tf.expand_dims(tf.to_float(tf.argmax(y_pred[...,:-12], axis=-1)), axis=-1)\n","        # Extract the confidences of the maximal classes.\n","        confidences = tf.reduce_max(y_pred[...,:-12], axis=-1, keep_dims=True)\n","\n","        # Convert anchor box offsets to image offsets.\n","        cx = y_pred[...,-12] * y_pred[...,-4] * y_pred[...,-6] + y_pred[...,-8] # cx = cx_pred * cx_variance * w_anchor + cx_anchor\n","        cy = y_pred[...,-11] * y_pred[...,-3] * y_pred[...,-5] + y_pred[...,-7] # cy = cy_pred * cy_variance * h_anchor + cy_anchor\n","        w = tf.exp(y_pred[...,-10] * y_pred[...,-2]) * y_pred[...,-6] # w = exp(w_pred * variance_w) * w_anchor\n","        h = tf.exp(y_pred[...,-9] * y_pred[...,-1]) * y_pred[...,-5] # h = exp(h_pred * variance_h) * h_anchor\n","\n","        # Convert 'centroids' to 'corners'.\n","        xmin = cx - 0.5 * w\n","        ymin = cy - 0.5 * h\n","        xmax = cx + 0.5 * w\n","        ymax = cy + 0.5 * h\n","\n","        # If the model predicts box coordinates relative to the image dimensions and they are supposed\n","        # to be converted back to absolute coordinates, do that.\n","        def normalized_coords():\n","            xmin1 = tf.expand_dims(xmin * self.tf_img_width, axis=-1)\n","            ymin1 = tf.expand_dims(ymin * self.tf_img_height, axis=-1)\n","            xmax1 = tf.expand_dims(xmax * self.tf_img_width, axis=-1)\n","            ymax1 = tf.expand_dims(ymax * self.tf_img_height, axis=-1)\n","            return xmin1, ymin1, xmax1, ymax1\n","        def non_normalized_coords():\n","            return tf.expand_dims(xmin, axis=-1), tf.expand_dims(ymin, axis=-1), tf.expand_dims(xmax, axis=-1), tf.expand_dims(ymax, axis=-1)\n","\n","        xmin, ymin, xmax, ymax = tf.cond(self.tf_normalize_coords, normalized_coords, non_normalized_coords)\n","\n","        # Concatenate the one-hot class confidences and the converted box coordinates to form the decoded predictions tensor.\n","        y_pred = tf.concat(values=[class_ids, confidences, xmin, ymin, xmax, ymax], axis=-1)\n","\n","        #####################################################################################\n","        # 2. Perform confidence thresholding, non-maximum suppression, and top-k filtering.\n","        #####################################################################################\n","\n","        batch_size = tf.shape(y_pred)[0] # Output dtype: tf.int32\n","        n_boxes = tf.shape(y_pred)[1]\n","        n_classes = y_pred.shape[2] - 4\n","        class_indices = tf.range(1, n_classes)\n","\n","        # Create a function that filters the predictions for the given batch item. Specifically, it performs:\n","        # - confidence thresholding\n","        # - non-maximum suppression (NMS)\n","        # - top-k filtering\n","        def filter_predictions(batch_item):\n","\n","            # Keep only the non-background boxes.\n","            positive_boxes = tf.not_equal(batch_item[...,0], 0.0)\n","            predictions = tf.boolean_mask(tensor=batch_item,\n","                                          mask=positive_boxes)\n","\n","            def perform_confidence_thresholding():\n","                # Apply confidence thresholding.\n","                threshold_met = predictions[:,1] > self.tf_confidence_thresh\n","                return tf.boolean_mask(tensor=predictions,\n","                                       mask=threshold_met)\n","            def no_positive_boxes():\n","                return tf.constant(value=0.0, shape=(1,6))\n","\n","            # If there are any positive predictions, perform confidence thresholding.\n","            predictions_conf_thresh = tf.cond(tf.equal(tf.size(predictions), 0), no_positive_boxes, perform_confidence_thresholding)\n","\n","            def perform_nms():\n","                scores = predictions_conf_thresh[...,1]\n","\n","                # `tf.image.non_max_suppression()` needs the box coordinates in the format `(ymin, xmin, ymax, xmax)`.\n","                xmin = tf.expand_dims(predictions_conf_thresh[...,-4], axis=-1)\n","                ymin = tf.expand_dims(predictions_conf_thresh[...,-3], axis=-1)\n","                xmax = tf.expand_dims(predictions_conf_thresh[...,-2], axis=-1)\n","                ymax = tf.expand_dims(predictions_conf_thresh[...,-1], axis=-1)\n","                boxes = tf.concat(values=[ymin, xmin, ymax, xmax], axis=-1)\n","\n","                maxima_indices = tf.image.non_max_suppression(boxes=boxes,\n","                                                              scores=scores,\n","                                                              max_output_size=self.tf_nms_max_output_size,\n","                                                              iou_threshold=self.iou_threshold,\n","                                                              name='non_maximum_suppresion')\n","                maxima = tf.gather(params=predictions_conf_thresh,\n","                                   indices=maxima_indices,\n","                                   axis=0)\n","                return maxima\n","            def no_confident_predictions():\n","                return tf.constant(value=0.0, shape=(1,6))\n","\n","            # If any boxes made the threshold, perform NMS.\n","            predictions_nms = tf.cond(tf.equal(tf.size(predictions_conf_thresh), 0), no_confident_predictions, perform_nms)\n","\n","            # Perform top-k filtering for this batch item or pad it in case there are\n","            # fewer than `self.top_k` boxes left at this point. Either way, produce a\n","            # tensor of length `self.top_k`. By the time we return the final results tensor\n","            # for the whole batch, all batch items must have the same number of predicted\n","            # boxes so that the tensor dimensions are homogenous. If fewer than `self.top_k`\n","            # predictions are left after the filtering process above, we pad the missing\n","            # predictions with zeros as dummy entries.\n","            def top_k():\n","                return tf.gather(params=predictions_nms,\n","                                 indices=tf.nn.top_k(predictions_nms[:, 1], k=self.tf_top_k, sorted=True).indices,\n","                                 axis=0)\n","            def pad_and_top_k():\n","                padded_predictions = tf.pad(tensor=predictions_nms,\n","                                            paddings=[[0, self.tf_top_k - tf.shape(predictions_nms)[0]], [0, 0]],\n","                                            mode='CONSTANT',\n","                                            constant_values=0.0)\n","                return tf.gather(params=padded_predictions,\n","                                 indices=tf.nn.top_k(padded_predictions[:, 1], k=self.tf_top_k, sorted=True).indices,\n","                                 axis=0)\n","\n","            top_k_boxes = tf.cond(tf.greater_equal(tf.shape(predictions_nms)[0], self.tf_top_k), top_k, pad_and_top_k)\n","\n","            return top_k_boxes\n","\n","        # Iterate `filter_predictions()` over all batch items.\n","        output_tensor = tf.map_fn(fn=lambda x: filter_predictions(x),\n","                                  elems=y_pred,\n","                                  dtype=None,\n","                                  parallel_iterations=128,\n","                                  back_prop=False,\n","                                  swap_memory=False,\n","                                  infer_shape=True,\n","                                  name='loop_over_batch')\n","\n","        return output_tensor\n","\n","    def compute_output_shape(self, input_shape):\n","        batch_size, n_boxes, last_axis = input_shape\n","        return (batch_size, self.tf_top_k, 6) # Last axis: (class_ID, confidence, 4 box coordinates)\n","\n","    def get_config(self):\n","        config = {\n","            'confidence_thresh': self.confidence_thresh,\n","            'iou_threshold': self.iou_threshold,\n","            'top_k': self.top_k,\n","            'nms_max_output_size': self.nms_max_output_size,\n","            'coords': self.coords,\n","            'normalize_coords': self.normalize_coords,\n","            'img_height': self.img_height,\n","            'img_width': self.img_width,\n","        }\n","        base_config = super(DecodeDetectionsFast, self).get_config()\n","        return dict(list(base_config.items()) + list(config.items()))"],"execution_count":1,"outputs":[]}]}