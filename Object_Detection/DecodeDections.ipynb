{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DecodeDections.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNCbdlbxDvNOVrPIJdLP3Ca"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"aF4QwIgJlRtU","executionInfo":{"status":"ok","timestamp":1621963945620,"user_tz":-420,"elapsed":2715,"user":{"displayName":"Hùng Nguyễn Lương","photoUrl":"","userId":"01503746792650000386"}}},"source":["'''\n","A custom Keras layer to decode the raw SSD prediction output. Corresponds to the\n","`DetectionOutput` layer type in the original Caffe implementation of SSD.\n","Copyright (C) 2018 Pierluigi Ferrari\n","Licensed under the Apache License, Version 2.0 (the \"License\");\n","you may not use this file except in compliance with the License.\n","You may obtain a copy of the License at\n","   http://www.apache.org/licenses/LICENSE-2.0\n","Unless required by applicable law or agreed to in writing, software\n","distributed under the License is distributed on an \"AS IS\" BASIS,\n","WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","See the License for the specific language governing permissions and\n","limitations under the License.\n","'''\n","\n","from __future__ import division\n","import numpy as np\n","import tensorflow as tf\n","import keras.backend as K\n","from keras.engine.topology import InputSpec\n","from keras.engine.topology import Layer\n","\n","class DecodeDetections(Layer):\n","    '''\n","    A Keras layer to decode the raw SSD prediction output.\n","    Input shape:\n","        3D tensor of shape `(batch_size, n_boxes, n_classes + 12)`.\n","    Output shape:\n","        3D tensor of shape `(batch_size, top_k, 6)`.\n","    '''\n","\n","    def __init__(self,\n","                 confidence_thresh=0.01,\n","                 iou_threshold=0.45,\n","                 top_k=200,\n","                 nms_max_output_size=400,\n","                 coords='centroids',\n","                 normalize_coords=True,\n","                 img_height=None,\n","                 img_width=None,\n","                 **kwargs):\n","        '''\n","        All default argument values follow the Caffe implementation.\n","        Arguments:\n","            confidence_thresh (float, optional): A float in [0,1), the minimum classification confidence in a specific\n","                positive class in order to be considered for the non-maximum suppression stage for the respective class.\n","                A lower value will result in a larger part of the selection process being done by the non-maximum suppression\n","                stage, while a larger value will result in a larger part of the selection process happening in the confidence\n","                thresholding stage.\n","            iou_threshold (float, optional): A float in [0,1]. All boxes with a Jaccard similarity of greater than `iou_threshold`\n","                with a locally maximal box will be removed from the set of predictions for a given class, where 'maximal' refers\n","                to the box score.\n","            top_k (int, optional): The number of highest scoring predictions to be kept for each batch item after the\n","                non-maximum suppression stage.\n","            nms_max_output_size (int, optional): The maximum number of predictions that will be left after performing non-maximum\n","                suppression.\n","            coords (str, optional): The box coordinate format that the model outputs. Must be 'centroids'\n","                i.e. the format `(cx, cy, w, h)` (box center coordinates, width, and height). Other coordinate formats are\n","                currently not supported.\n","            normalize_coords (bool, optional): Set to `True` if the model outputs relative coordinates (i.e. coordinates in [0,1])\n","                and you wish to transform these relative coordinates back to absolute coordinates. If the model outputs\n","                relative coordinates, but you do not want to convert them back to absolute coordinates, set this to `False`.\n","                Do not set this to `True` if the model already outputs absolute coordinates, as that would result in incorrect\n","                coordinates. Requires `img_height` and `img_width` if set to `True`.\n","            img_height (int, optional): The height of the input images. Only needed if `normalize_coords` is `True`.\n","            img_width (int, optional): The width of the input images. Only needed if `normalize_coords` is `True`.\n","        '''\n","        if K.backend() != 'tensorflow':\n","            raise TypeError(\"This layer only supports TensorFlow at the moment, but you are using the {} backend.\".format(K.backend()))\n","\n","        if normalize_coords and ((img_height is None) or (img_width is None)):\n","            raise ValueError(\"If relative box coordinates are supposed to be converted to absolute coordinates, the decoder needs the image size in order to decode the predictions, but `img_height == {}` and `img_width == {}`\".format(img_height, img_width))\n","\n","        if coords != 'centroids':\n","            raise ValueError(\"The DetectionOutput layer currently only supports the 'centroids' coordinate format.\")\n","\n","        # We need these members for the config.\n","        self.confidence_thresh = confidence_thresh\n","        self.iou_threshold = iou_threshold\n","        self.top_k = top_k\n","        self.normalize_coords = normalize_coords\n","        self.img_height = img_height\n","        self.img_width = img_width\n","        self.coords = coords\n","        self.nms_max_output_size = nms_max_output_size\n","\n","        # We need these members for TensorFlow.\n","        self.tf_confidence_thresh = tf.constant(self.confidence_thresh, name='confidence_thresh')\n","        self.tf_iou_threshold = tf.constant(self.iou_threshold, name='iou_threshold')\n","        self.tf_top_k = tf.constant(self.top_k, name='top_k')\n","        self.tf_normalize_coords = tf.constant(self.normalize_coords, name='normalize_coords')\n","        self.tf_img_height = tf.constant(self.img_height, dtype=tf.float32, name='img_height')\n","        self.tf_img_width = tf.constant(self.img_width, dtype=tf.float32, name='img_width')\n","        self.tf_nms_max_output_size = tf.constant(self.nms_max_output_size, name='nms_max_output_size')\n","\n","        super(DecodeDetections, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        self.input_spec = [InputSpec(shape=input_shape)]\n","        super(DecodeDetections, self).build(input_shape)\n","\n","    def call(self, y_pred, mask=None):\n","        '''\n","        Returns:\n","            3D tensor of shape `(batch_size, top_k, 6)`. The second axis is zero-padded\n","            to always yield `top_k` predictions per batch item. The last axis contains\n","            the coordinates for each predicted box in the format\n","            `[class_id, confidence, xmin, ymin, xmax, ymax]`.\n","        '''\n","\n","        #####################################################################################\n","        # 1. Convert the box coordinates from predicted anchor box offsets to predicted\n","        #    absolute coordinates\n","        #####################################################################################\n","\n","        # Convert anchor box offsets to image offsets.\n","        cx = y_pred[...,-12] * y_pred[...,-4] * y_pred[...,-6] + y_pred[...,-8] # cx = cx_pred * cx_variance * w_anchor + cx_anchor\n","        cy = y_pred[...,-11] * y_pred[...,-3] * y_pred[...,-5] + y_pred[...,-7] # cy = cy_pred * cy_variance * h_anchor + cy_anchor\n","        w = tf.exp(y_pred[...,-10] * y_pred[...,-2]) * y_pred[...,-6] # w = exp(w_pred * variance_w) * w_anchor\n","        h = tf.exp(y_pred[...,-9] * y_pred[...,-1]) * y_pred[...,-5] # h = exp(h_pred * variance_h) * h_anchor\n","\n","        # Convert 'centroids' to 'corners'.\n","        xmin = cx - 0.5 * w\n","        ymin = cy - 0.5 * h\n","        xmax = cx + 0.5 * w\n","        ymax = cy + 0.5 * h\n","\n","        # If the model predicts box coordinates relative to the image dimensions and they are supposed\n","        # to be converted back to absolute coordinates, do that.\n","        def normalized_coords():\n","            xmin1 = tf.expand_dims(xmin * self.tf_img_width, axis=-1)\n","            ymin1 = tf.expand_dims(ymin * self.tf_img_height, axis=-1)\n","            xmax1 = tf.expand_dims(xmax * self.tf_img_width, axis=-1)\n","            ymax1 = tf.expand_dims(ymax * self.tf_img_height, axis=-1)\n","            return xmin1, ymin1, xmax1, ymax1\n","        def non_normalized_coords():\n","            return tf.expand_dims(xmin, axis=-1), tf.expand_dims(ymin, axis=-1), tf.expand_dims(xmax, axis=-1), tf.expand_dims(ymax, axis=-1)\n","\n","        xmin, ymin, xmax, ymax = tf.cond(self.tf_normalize_coords, normalized_coords, non_normalized_coords)\n","\n","        # Concatenate the one-hot class confidences and the converted box coordinates to form the decoded predictions tensor.\n","        y_pred = tf.concat(values=[y_pred[...,:-12], xmin, ymin, xmax, ymax], axis=-1)\n","\n","        #####################################################################################\n","        # 2. Perform confidence thresholding, per-class non-maximum suppression, and\n","        #    top-k filtering.\n","        #####################################################################################\n","\n","        batch_size = tf.shape(y_pred)[0] # Output dtype: tf.int32\n","        n_boxes = tf.shape(y_pred)[1]\n","        n_classes = y_pred.shape[2] - 4\n","        class_indices = tf.range(1, n_classes)\n","\n","        # Create a function that filters the predictions for the given batch item. Specifically, it performs:\n","        # - confidence thresholding\n","        # - non-maximum suppression (NMS)\n","        # - top-k filtering\n","        def filter_predictions(batch_item):\n","\n","            # Create a function that filters the predictions for one single class.\n","            def filter_single_class(index):\n","\n","                # From a tensor of shape (n_boxes, n_classes + 4 coordinates) extract\n","                # a tensor of shape (n_boxes, 1 + 4 coordinates) that contains the\n","                # confidnece values for just one class, determined by `index`.\n","                confidences = tf.expand_dims(batch_item[..., index], axis=-1)\n","                class_id = tf.fill(dims=tf.shape(confidences), value=tf.to_float(index))\n","                box_coordinates = batch_item[...,-4:]\n","\n","                single_class = tf.concat([class_id, confidences, box_coordinates], axis=-1)\n","\n","                # Apply confidence thresholding with respect to the class defined by `index`.\n","                threshold_met = single_class[:,1] > self.tf_confidence_thresh\n","                single_class = tf.boolean_mask(tensor=single_class,\n","                                               mask=threshold_met)\n","\n","                # If any boxes made the threshold, perform NMS.\n","                def perform_nms():\n","                    scores = single_class[...,1]\n","\n","                    # `tf.image.non_max_suppression()` needs the box coordinates in the format `(ymin, xmin, ymax, xmax)`.\n","                    xmin = tf.expand_dims(single_class[...,-4], axis=-1)\n","                    ymin = tf.expand_dims(single_class[...,-3], axis=-1)\n","                    xmax = tf.expand_dims(single_class[...,-2], axis=-1)\n","                    ymax = tf.expand_dims(single_class[...,-1], axis=-1)\n","                    boxes = tf.concat(values=[ymin, xmin, ymax, xmax], axis=-1)\n","\n","                    maxima_indices = tf.image.non_max_suppression(boxes=boxes,\n","                                                                  scores=scores,\n","                                                                  max_output_size=self.tf_nms_max_output_size,\n","                                                                  iou_threshold=self.iou_threshold,\n","                                                                  name='non_maximum_suppresion')\n","                    maxima = tf.gather(params=single_class,\n","                                       indices=maxima_indices,\n","                                       axis=0)\n","                    return maxima\n","\n","                def no_confident_predictions():\n","                    return tf.constant(value=0.0, shape=(1,6))\n","\n","                single_class_nms = tf.cond(tf.equal(tf.size(single_class), 0), no_confident_predictions, perform_nms)\n","\n","                # Make sure `single_class` is exactly `self.nms_max_output_size` elements long.\n","                padded_single_class = tf.pad(tensor=single_class_nms,\n","                                             paddings=[[0, self.tf_nms_max_output_size - tf.shape(single_class_nms)[0]], [0, 0]],\n","                                             mode='CONSTANT',\n","                                             constant_values=0.0)\n","\n","                return padded_single_class\n","\n","            # Iterate `filter_single_class()` over all class indices.\n","            filtered_single_classes = tf.map_fn(fn=lambda i: filter_single_class(i),\n","                                                elems=tf.range(1,n_classes),\n","                                                dtype=tf.float32,\n","                                                parallel_iterations=128,\n","                                                back_prop=False,\n","                                                swap_memory=False,\n","                                                infer_shape=True,\n","                                                name='loop_over_classes')\n","\n","            # Concatenate the filtered results for all individual classes to one tensor.\n","            filtered_predictions = tf.reshape(tensor=filtered_single_classes, shape=(-1,6))\n","\n","            # Perform top-k filtering for this batch item or pad it in case there are\n","            # fewer than `self.top_k` boxes left at this point. Either way, produce a\n","            # tensor of length `self.top_k`. By the time we return the final results tensor\n","            # for the whole batch, all batch items must have the same number of predicted\n","            # boxes so that the tensor dimensions are homogenous. If fewer than `self.top_k`\n","            # predictions are left after the filtering process above, we pad the missing\n","            # predictions with zeros as dummy entries.\n","            def top_k():\n","                return tf.gather(params=filtered_predictions,\n","                                 indices=tf.nn.top_k(filtered_predictions[:, 1], k=self.tf_top_k, sorted=True).indices,\n","                                 axis=0)\n","            def pad_and_top_k():\n","                padded_predictions = tf.pad(tensor=filtered_predictions,\n","                                            paddings=[[0, self.tf_top_k - tf.shape(filtered_predictions)[0]], [0, 0]],\n","                                            mode='CONSTANT',\n","                                            constant_values=0.0)\n","                return tf.gather(params=padded_predictions,\n","                                 indices=tf.nn.top_k(padded_predictions[:, 1], k=self.tf_top_k, sorted=True).indices,\n","                                 axis=0)\n","\n","            top_k_boxes = tf.cond(tf.greater_equal(tf.shape(filtered_predictions)[0], self.tf_top_k), top_k, pad_and_top_k)\n","\n","            return top_k_boxes\n","\n","        # Iterate `filter_predictions()` over all batch items.\n","        output_tensor = tf.map_fn(fn=lambda x: filter_predictions(x),\n","                                  elems=y_pred,\n","                                  dtype=None,\n","                                  parallel_iterations=128,\n","                                  back_prop=False,\n","                                  swap_memory=False,\n","                                  infer_shape=True,\n","                                  name='loop_over_batch')\n","\n","        return output_tensor\n","\n","    def compute_output_shape(self, input_shape):\n","        batch_size, n_boxes, last_axis = input_shape\n","        return (batch_size, self.tf_top_k, 6) # Last axis: (class_ID, confidence, 4 box coordinates)\n","\n","    def get_config(self):\n","        config = {\n","            'confidence_thresh': self.confidence_thresh,\n","            'iou_threshold': self.iou_threshold,\n","            'top_k': self.top_k,\n","            'nms_max_output_size': self.nms_max_output_size,\n","            'coords': self.coords,\n","            'normalize_coords': self.normalize_coords,\n","            'img_height': self.img_height,\n","            'img_width': self.img_width,\n","        }\n","        base_config = super(DecodeDetections, self).get_config()\n","        return dict(list(base_config.items()) + list(config.items()))"],"execution_count":1,"outputs":[]}]}